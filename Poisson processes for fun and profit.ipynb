{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_cell": true
   },
   "source": [
    "**SA402 &#x25aa; Dynamic and Stochastic Models &#x25aa; Fall 2022**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson processes for fun and profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A really important question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do BTS's tweets follow a Poisson process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we determine if an arrival process is Poisson?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One approach: __look at the interarrival times__.\n",
    "    * Are the interarrival times exponentially distributed?\n",
    "    * Are the interarrival times independent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, we need to import a whole bunch of libraries, including [Tweepy](http://www.tweepy.org), which allows us to interface with Twitter programmatically using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, we need to authenticate into Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = 'BEARER_TOKEN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting someone's tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's first test Tweepy by grabbing some basic information about the Twitter user we want to study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'BTS_twt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.get_user(username=username, user_fields=['profile_image_url'])\n",
    "user = response.data\n",
    "\n",
    "print(f'Name: {user.username}')\n",
    "IPython.display.Image(user.profile_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, let's grab this user's last 200 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tweets = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets = []\n",
    "for tweet in tweepy.Paginator(\n",
    "    client.get_users_tweets, user.id, \n",
    "    max_results=100, tweet_fields=['created_at']\n",
    ").flatten(limit=n_tweets):\n",
    "    public_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, we'll put the arrival time and text of each tweet into a __Pandas DataFrame__, which will let us analyze our data more easily.\n",
    "    - [**Pandas**](https://pandas.pydata.org/) is a Python library for data manipulation and analysis.\n",
    "    - You can think of a __DataFrame__ as a two-dimensional table, with rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets_raw_df = pd.DataFrame.from_records(\n",
    "    [[tweet.created_at, tweet.text] for tweet in public_tweets],\n",
    "    columns=['arrival_time', 'text']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Just to make sure we're doing this right &mdash; let's examine some of this user's tweets by viewing the first 5 rows of this DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets_raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the observed interarrival times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's treat each tweet as an *observation*.\n",
    "\n",
    "\n",
    "* We can compute the observed interarrival times by:\n",
    "    - sorting the data by the arrival times in ascending order, and then \n",
    "    - computing the difference between consecutive arrival times.\n",
    "\n",
    "\n",
    "* We convert the time differences to seconds, and then divide by $60 \\times 60$ to obtain the time differences in hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets_df = (\n",
    "    public_tweets_raw_df\n",
    "    .sort_values('arrival_time', ascending=True)\n",
    "    .assign(\n",
    "        interarrival_time=lambda x: x['arrival_time'].diff(periods=1).dt.total_seconds() / (60 * 60)\n",
    "    )\n",
    ")\n",
    "\n",
    "public_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a histogram of the observed interarrival times in our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now that we have the observed interarrival times, let's visualize them with a histogram.\n",
    "\n",
    "\n",
    "* We will use [**Altair**](https://altair-viz.github.io/), a modern Python visualization library.\n",
    "\n",
    "\n",
    "* First, a little setup:\n",
    "    * We specify the number of bins we want in our histogram.\n",
    "    * Based on the maximum observed interarrival time in our data, we can then compute the width of each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_interarrival_time = public_tweets_df['interarrival_time'].max()\n",
    "print(f'Maximum interarrival time: {max_interarrival_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_width = math.ceil(max_interarrival_time / n_bins)\n",
    "print(f'Bin width: {bin_width}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = alt.Chart(public_tweets_df).mark_bar().encode(\n",
    "    alt.X('interarrival_time:Q', \n",
    "          bin=alt.BinParams(step=bin_width),\n",
    "          title='Interarrival time'),\n",
    "    alt.Y('count():Q', title='Count')\n",
    ")\n",
    "\n",
    "histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the observed interarrival times to an exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We want to see if the observed interarrival times fit an exponential distribution. \n",
    "\n",
    "* Recall that the exponential distribution has a parameter $\\lambda$, which would correspond to the arrival rate of a Poisson process.\n",
    "\n",
    "* What should we use for $\\lambda$?\n",
    "\n",
    "* It turns out that the __maximum likelihood estimator (MLE)__ is\n",
    "\n",
    "$$\n",
    "\\hat{\\lambda} = \\frac{1}{\\text{sample mean of the observed interarrival times}}\n",
    "$$\n",
    "\n",
    "* Let's compute this next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean_interarrival_time = public_tweets_df['interarrival_time'].mean()\n",
    "print(f'Sample mean of observed interarrival times: {sample_mean_interarrival_time:.4f} hours per tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_arrival_rate = 1 / sample_mean_interarrival_time\n",
    "print(f'Estimated arrival rate: {estimated_arrival_rate:.4f} tweets per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the pdf of the MLE exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's plot the pdf of the MLE exponential distribution &mdash; the exponential distribution with parameter $\\hat{\\lambda}$ we found above.\n",
    "\n",
    "\n",
    "* First, we need to create a DataFrame with the values of the MLE exponential distribution pdf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = 1000\n",
    "\n",
    "interarrival_time_values = [i * max_interarrival_time / n_values for i in range(n_values)]\n",
    "density_values = [stats.expon.pdf(x, scale=1 / estimated_arrival_rate) for x in interarrival_time_values]\n",
    "\n",
    "exponential_density_df = pd.DataFrame(\n",
    "    {\n",
    "        'interarrival_time': interarrival_time_values,\n",
    "        'density': density_values\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's check our work by examining the first 5 rows of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_density_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we can use Altair to plot the pdf of the MLE exponential distribution.\n",
    "    * We need to scale the pdf values to match the area under the histogram of observed interarrival times.\n",
    "    * The area under the (unscaled) pdf is 1. \n",
    "    * The area under the histogram is `n_tweets * bin_width`. (Why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = alt.Chart(exponential_density_df).transform_calculate(\n",
    "    scaled_density=f'datum.density * {n_tweets} * {bin_width}'\n",
    ").mark_line(color='red').encode(\n",
    "    alt.X('interarrival_time:Q', title='Interarrival time'),\n",
    "    alt.Y('scaled_density:Q', title='Density')\n",
    ")\n",
    "\n",
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the histogram of observed interarrival times and the MLE exponential pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To more easily compare the histogram of observed interarrival times and the MLE exponential pdf, we can simply add them together in Altair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram + pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤” __What do you think?__  __Are the interarrival times exponentially distributed?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ideally, we would perform some goodness-of-fit tests to statistically determine whether the exponential distribution is a good fit for the interarrival times. \n",
    "    - This is covered in _SA421 Simulation Modeling_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for independence of the interarrival times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We also need to check independence of the interarrival times. One easy visual test is to plot the interarrival times as a time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(public_tweets_df).mark_line().encode(\n",
    "    alt.X('arrival_time:O', title='Arrival time'),\n",
    "    alt.Y('interarrival_time:Q', title='Interarrival time')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤” __What do you think? Are the interarrival times independent?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤” __What type of user would you expect to tweet according to a Poisson process?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #poisson?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can also do the same thing with hashtags. Let's grab the last 200 tweets with a certain hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_text = \"#gonavy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tweets = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_tweets = []\n",
    "for tweet in tweepy.Paginator(\n",
    "    client.search_recent_tweets, search_text, \n",
    "    max_results=100, tweet_fields=['created_at']\n",
    ").flatten(limit=n_tweets):\n",
    "    hashtag_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_tweets_df = (\n",
    "    pd.DataFrame.from_records(\n",
    "        [[tweet.created_at, tweet.text] for tweet in hashtag_tweets],\n",
    "        columns=['arrival_time', 'text']\n",
    "    )\n",
    "    .sort_values('arrival_time', ascending=True)\n",
    "    .assign(\n",
    "        interarrival_time=lambda x: x['arrival_time'].diff(periods=1).dt.total_seconds() / 60\n",
    "    )\n",
    ")\n",
    "\n",
    "hashtag_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, we can go through the same process as we did above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_interarrival_time = hashtag_tweets_df['interarrival_time'].max()\n",
    "sample_mean_interarrival_time = hashtag_tweets_df['interarrival_time'].mean()\n",
    "estimated_arrival_rate = 1 / sample_mean_interarrival_time\n",
    "\n",
    "n_values = 1000\n",
    "exponential_density_df = pd.DataFrame(\n",
    "    {\n",
    "        'interarrival_time': [i * max_interarrival_time / n_values for i in range(n_values)],\n",
    "        'density': [stats.expon.pdf(x, scale=1 / estimated_arrival_rate) for x in interarrival_time_values]\n",
    "    }\n",
    ")\n",
    "\n",
    "n_bins = 20\n",
    "bin_width = math.ceil(max_interarrival_time / n_bins)\n",
    "\n",
    "histogram = alt.Chart(hashtag_tweets_df).mark_bar().encode(\n",
    "    alt.X('interarrival_time:Q', \n",
    "          bin=alt.BinParams(step=bin_width),\n",
    "          title='Interarrival time'),\n",
    "    alt.Y('count():Q', title='Count')\n",
    ")\n",
    "\n",
    "pdf = alt.Chart(exponential_density_df).transform_calculate(\n",
    "    scaled_density=f'datum.density * {n_tweets} * {bin_width}'\n",
    ").mark_line(color='red').encode(\n",
    "    alt.X('interarrival_time:Q', title='Interarrival time'),\n",
    "    alt.Y('scaled_density:Q', title='Density')\n",
    ")\n",
    "\n",
    "histogram + pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤” __What do you think? Are the interarrival times from an exponential distribution?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(hashtag_tweets_df).mark_line().encode(\n",
    "    alt.X('arrival_time:O', title='Arival time'),\n",
    "    alt.Y('interarrival_time:Q', title='Interarrrival time')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤” __Are the interarrival times independent?__\n",
    "\n",
    "ðŸ¤” __What type of hashtag would you expect to follow a Poisson process?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shameless plug ðŸ˜¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you'd like to learn how to\n",
    "    - visualize data with Altair, and\n",
    "    - wrangle data with Pandas,\n",
    "  \n",
    "  just like in this lesson, sign up for _SA463A Data Wrangling and Visualization_!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
